 ### Desafio_Final_Big_Data
 
<h1 align="center"> Pipeline de Dados </h1>
<h4 align="center">Projeto final para o programa Jovens Profissionais BI/BA realizado pela Minsait Indra, com intuito de apresentar as habilidades adquiridas durante a jornada de aprendizado no programa.</h4>
<h4 tabindex="-1" dir="auto">üìå Principais tecnologias utilizadas</h4>

![MySQL](https://img.shields.io/badge/mysql-%2300f.svg?style=for-the-badge&logo=mysql&logoColor=white) ![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54) ![Shell Script](https://img.shields.io/badge/shell_script-%23121011.svg?style=for-the-badge&logo=gnu-bash&logoColor=white) ![Gitpod](https://img.shields.io/badge/gitpod-f06611.svg?style=for-the-badge&logo=gitpod&logoColor=white) ![Git](https://img.shields.io/badge/GIT-E44C30?style=for-the-badge&logo=git&logoColor=white) ![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white) ![Linux](https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&logo=linux&logoColor=black) ![Apache](https://img.shields.io/badge/apache-%23D42029.svg?style=for-the-badge&logo=apache&logoColor=white)

<h4 tabindex="-1" dir="auto"></a> üìç Descri√ß√£o do projeto</h4>

Nesse projeto foi apresentado um desenvolvimento de um Pipeline de ingest√£o de dados utilizando Hive na arquitetura do Apache Hadoop juntamente com o processamento e tratamento dos dados com Spark. Projeto feito para ser usado pela √°rea de Business Intelligence utilizar para an√°lises no PowerBI e realizar a tomada de decis√µes


<h4 tabindex="-1" dir="auto">‚öíÔ∏è Constru√ß√£o do Projeto ‚öíÔ∏è</h4>
Para a movimenta√ß√£o e cria√ß√£o de pastas dentro do HDFS e tamb√©m da cria√ß√£o das tabelas externas no Hive foi utilizado ShellScript para a automa√ß√£o do processo.
<br></br>
Foram utilizadas tabelas de vendas, clientes, endere√ßo, regi√£o, divis√£o com esses dados foi necess√°rio realizar a desnormatiza√ß√£o das tabelas e transforma-las em um modelo dimensional de formato estrela.
Para isso, utilizando linguagem SQL dentro do Spark, foi realizado diversos joins para que fosse poss√≠vel chegar ao resultado esperado, al√©m da necessidade de tratar os dados de acordo com a necessidade do cliente, como por exemplo preencher campos string vazios com "N√£o informado", etc.
<br></br>
Ap√≥s o tratamento de dados e a cria√ß√£o do nosso modelo estrela, com as tabelas tratadas criamos nossa estrutura no PowerBI para que a √°rea de Business Intelligence consiga realizar consultas e an√°lises para tomada de decis√µes.
<br></br>

![image](https://user-images.githubusercontent.com/126920974/230743241-db2c1ee3-cc80-432c-9803-c641f210c64f.png)
<br></br>
<h4 tabindex="-1" dir="auto">üìö Principais conceitos aprendidos</h4>
<li> 5 Vs do Big Data e sua import√¢ncia para √°nalise de dados </li>
<li> Modelo estrela x Snowflake </li>
<li> Conceitos de Docker e Manipula√ß√£o dos cont√™ineres </li>
<li> Hadoop e sua arquitetura </li>
<li> Namenode x Datanode e sua rela√ß√£o com o HDFS </li>
<li> Comandos Linux </li>
<li> Conceitos de Datalake </li>
<li> ETL x ELT </li>
<li> Tabelas internas e externas no Hive </li>
<li> Tabela stage e desnormatiza√ß√£o de dados </li>
<li> PowerBI para apresenta√ß√£o das informa√ß√µes </li>

